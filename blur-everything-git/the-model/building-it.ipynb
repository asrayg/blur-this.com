{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Face Detection and Blurring Model\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "1. **Data Collection**\n",
    "   - Use the [WIDER FACE dataset](http://shuoyang1213.me/WIDERFACE/).\n",
    "\n",
    "2. **Model Architecture**\n",
    "   - Design a Convolutional Neural Network (CNN) for face detection.\n",
    "\n",
    "3. **Data Preprocessing**\n",
    "   - Resize and normalize images.\n",
    "   - Extract bounding boxes from annotations.\n",
    "\n",
    "4. **Training**\n",
    "   - Train the CNN model with the dataset.\n",
    "\n",
    "5. **Face Detection and Blurring**\n",
    "   - Detect and blur faces in new images using the trained model.\n",
    "\n",
    "6. **Evaluation**\n",
    "   - Evaluate the model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_face_detection_model(input_shape=(128, 128, 3)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(4))  # [x, y, width, height] for bounding box\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_face_detection_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, img_size=(128, 128)):\n",
    "    images = []\n",
    "    bboxes = []\n",
    "\n",
    "    for subdir, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                xml_path = os.path.join(subdir, file.replace('.jpg', '.xml'))\n",
    "                \n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, img_size)\n",
    "                image = image / 255.0\n",
    "                \n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "                bbox = root.find('object').find('bndbox')\n",
    "                \n",
    "                xmin = int(bbox.find('xmin').text)\n",
    "                ymin = int(bbox.find('ymin').text)\n",
    "                xmax = int(bbox.find('xmax').text)\n",
    "                ymax = int(bbox.find('ymax').text)\n",
    "                \n",
    "                width = xmax - xmin\n",
    "                height = ymax - ymin\n",
    "                \n",
    "                # Normalize bounding box coordinates\n",
    "                bbox = [xmin / img_size[0], ymin / img_size[1], width / img_size[0], height / img_size[1]]\n",
    "                \n",
    "                images.append(image)\n",
    "                bboxes.append(bbox)\n",
    "    \n",
    "    return np.array(images), np.array(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_data('path_to_widerface_train')\n",
    "X_val, Y_val = load_data('path_to_widerface_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(X_train, Y_train, batch_size=32)\n",
    "val_generator = datagen.flow(X_val, Y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=50, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_faces_in_image(model, image):\n",
    "    input_image = cv2.resize(image, (128, 128))\n",
    "    input_image = input_image / 255.0\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "    \n",
    "    bbox = model.predict(input_image)[0]\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    x = int(x * w)\n",
    "    y = int(y * h)\n",
    "    width = int(w * w)\n",
    "    height = int(h * h)\n",
    "    \n",
    "    face_region = image[y:y+height, x:x+width]\n",
    "    face_region = cv2.GaussianBlur(face_region, (99, 99), 30)\n",
    "    \n",
    "    image[y:y+height, x:x+width] = face_region\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('add_your_path_here_uwu.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = blur_faces_in_image(model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Blurred Faces', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(val_generator)\n",
    "print(f'Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face_detection_model.h5')\n",
    "!mmtoir -f keras -w face_detection_model.h5 -o face_detection_model\n",
    "!mmtocode -f caffe -n face_detection_model.pb -w face_detection_model.npy -o face_detection_model\n",
    "!mmtomodel -f caffe -n face_detection_model.py -w face_detection_model.npy -o face_detection_model.caffemodel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is finished. Gets saved as face-detecting-model.caffemodel"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
